{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[comment]: # (Attach Default Lakehouse Markdown Cell)\n",
    "# üìå Attach Default Lakehouse\n",
    "‚ùó**Note the code in the cell that follows is required to programatically attach the lakehouse and enable the running of spark.sql(). If this cell fails simply restart your session as this cell MUST be the first command executed on session start.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%configure\n",
    "{\n",
    "    \"defaultLakehouse\": {  \n",
    "        \"name\": \"{{lakehouse_name}}\",\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üì¶ Pip\n",
    "Pip installs reqired specifically for this template should occur here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# No pip installs needed for this notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üîó Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from notebookutils import mssparkutils # type: ignore"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# #Ô∏è‚É£ Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pre_execute_notebook(notebook_file):\n",
    "\n",
    "    try:\n",
    "        mssparkutils.notebook.run(notebook_file, {{ notebook_timeout }})\n",
    "        status = 'PreExecute Notebook Executed'\n",
    "        error = None\n",
    "    except Exception as e:\n",
    "        status = 'No PreExecute Notebook Found'\n",
    "        error = str(e)\n",
    "\n",
    "    return status\n",
    "\n",
    "def post_execute_notebook(notebook_file):\n",
    "\n",
    "    try:\n",
    "        mssparkutils.notebook.run(notebook_file, {{ notebook_timeout }})\n",
    "        status = 'PostExecute Notebook Executed'\n",
    "        error = None\n",
    "    except Exception as e:\n",
    "        status = 'No PostExecute Notebook Found'\n",
    "        error = str(e)\n",
    "\n",
    "    return status"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre-Execution Python Script"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Declare and Execute Pre-Execution Notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Read the context of the notebook\n",
    "notebook_info = mssparkutils.runtime.context\n",
    "\n",
    "# Extract the currentNotebookName from the dictionary\n",
    "current_notebook_name = notebook_info.get(\"currentNotebookName\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Execute Pre-Execute Notebook\n",
    "preexecute_notebook_name  = current_notebook_name+ \".preexecute\"\n",
    "pre_execute_notebook(preexecute_notebook_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Declare and Execute SQL Statements"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üõë Execution Stop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Execute Post-Execute Notebook\n",
    "postexecute_notebook_name  = current_notebook_name + \".postexecute\"\n",
    "post_execute_notebook(postexecute_notebook_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Exit to prevent spark sql debug cell running \n",
    "mssparkutils.notebook.exit(\"value string\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SPARK SQL Cells for Debugging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql\n",
    "        create or replace table lh_gold.order_territory1\n",
    "      as\n",
    "-- CTE to rank CDC records by Id, meta_ExtractedDate, and SYS_CHANGE_VERSION\n",
    "WITH source_data AS (\n",
    "SELECT \tCASE WHEN ord.SalesOrderID < 50000 THEN\t\n",
    "      MD5(\n",
    "        CONCAT_WS(\n",
    "          '||',COALESCE(CAST(ord.TerritoryID AS string), '__NULL__'),COALESCE(CAST(tr.Group AS string), '__NULL__'),COALESCE(CAST(ord.SalesOrderID AS string), '__NULL__'))\n",
    "      ) ELSE 'NA' END AS order_sk,\n",
    "\t\t\t--md5(cast(concat(coalesce(cast(ord.TerritoryID as string), '_dbt_utils_surrogate_key_null_'), '-', coalesce(cast(tr.Group as string), '_dbt_utils_surrogate_key_null_'), '-', coalesce(cast(ord.SalesOrderID as string), '_dbt_utils_surrogate_key_null_')) as string)) AS order_sk,\n",
    "\t\t\tord.SalesOrderID as SalesOrderID,\n",
    "\t\t\tord.TerritoryID,\n",
    "\t\t\ttr.Name as TerritoryName,\n",
    "\t\t\ttr.Group as TerritoryGroup,\n",
    "\t\t\tord.TaxAmt,\n",
    "\t\t\tord.Freight,\n",
    "\t\t\tord.TotalDue,\n",
    "\t\t\tord.Comment,\n",
    "\t\t\tord.ModifiedDate\n",
    "FROM lh_silver.orders  ord\n",
    "LEFT JOIN lh_silver.territories  tr\n",
    "ON ord.TerritoryID = tr.TerritoryID\n",
    ")\n",
    "select * from source_data"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}